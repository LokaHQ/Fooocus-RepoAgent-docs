## ClassDef LCM
**LCM**: The function of LCM is to perform denoising operations on model outputs using a specific noise scaling approach based on the sigma value.

**attributes**: The attributes of this Class.
· sigma_data: Represents a constant value used in noise calculations.

**Code Description**: The LCM class inherits from the EPS class, which is designed to handle noise estimation and scaling in a model sampling context. The primary method in the LCM class is `calculate_denoised`, which takes three parameters: `sigma`, `model_output`, and `model_input`. 

In the `calculate_denoised` method, the following operations are performed:

1. The `timestep` is calculated by calling the `timestep` method of the EPS class, which is expected to return a tensor based on the provided `sigma`. This tensor is reshaped to match the dimensions of the `model_output`.

2. The `sigma` parameter is also reshaped to align with the dimensions of the `model_output`.

3. The denoised image `x0` is computed by subtracting the product of `model_output` and `sigma` from the `model_input`. This operation effectively reduces the noise in the model output based on the provided sigma.

4. A constant value `sigma_data` is defined, which is used in subsequent calculations.

5. The `scaled_timestep` is calculated by multiplying the `timestep` by a factor of 10.0, which serves as a scaling factor for the timestep.

6. Two coefficients, `c_skip` and `c_out`, are computed. `c_skip` represents the contribution of the original model input to the denoised output, while `c_out` represents the contribution of the denoised image.

7. Finally, the method returns a combination of the denoised image and the original model input, weighted by the coefficients `c_out` and `c_skip`.

The LCM class is utilized within the `patch` method of the ModelSamplingDiscrete class in the external_model_advanced.py module. When the sampling type is specified as "lcm", an instance of the LCM class is created and combined with a base sampling class to form a new class, ModelSamplingAdvanced. This new class inherits the functionality of both the base sampling class and the LCM class, allowing it to perform advanced sampling operations that include the denoising capabilities of the LCM class.

**Note**: When using the LCM class, it is crucial to ensure that the input tensors (sigma, model_output, model_input) are appropriately shaped to avoid dimension mismatch errors during calculations. Additionally, the behavior of the LCM class is dependent on the EPS class, so understanding the methods and attributes of EPS is beneficial for effective usage.

**Output Example**: A possible output of the `calculate_denoised` method could be a tensor representing the denoised version of the input image. For instance, if the `model_input` tensor is [0.8, 0.6, 0.4] and the `model_output` tensor is [0.1, 0.2, 0.3] with a `sigma` of [0.05], the output might look like a tensor that represents the denoised image, calculated according to the operations defined in the method.
### FunctionDef calculate_denoised(self, sigma, model_output, model_input)
**calculate_denoised**: The function of calculate_denoised is to compute a denoised output based on the provided noise level, model output, and model input.

**parameters**: The parameters of this Function.
· sigma: A tensor representing the noise level to be considered in the denoising process.  
· model_output: A tensor that contains the output generated by the model, which is subject to noise.  
· model_input: A tensor that represents the original input data before noise was applied.  

**Code Description**: The calculate_denoised function performs a denoising operation by utilizing the provided parameters. Initially, it calculates a timestep based on the noise level (sigma) and reshapes it to match the dimensions of the model output. The sigma parameter is also reshaped similarly to ensure compatibility in subsequent calculations. The function then computes an intermediate variable, x0, which represents an estimate of the original data by subtracting the product of the model output and the noise level from the model input.

Next, the function defines a constant sigma_data, which is set to 0.5, and scales the timestep by a factor of 10. This scaling is crucial for adjusting the timestep in relation to the noise level. Two coefficients, c_skip and c_out, are then calculated. c_skip is determined by the ratio of the square of sigma_data to the sum of the squares of the scaled timestep and sigma_data, while c_out is derived from the scaled timestep divided by the square root of the sum of the squares of the scaled timestep and sigma_data.

Finally, the function returns a combination of the denoised estimate (c_out * x0) and a weighted contribution of the original model input (c_skip * model_input), effectively blending the denoised output with the original input based on the calculated coefficients.

**Note**: It is important to ensure that the dimensions of the input tensors are compatible for the operations performed within this function. The scaling factor and the constant sigma_data can be adjusted based on specific denoising requirements.

**Output Example**: A possible return value of the function could be a tensor representing the denoised output, which may look like this:  
tensor([[0.8, 0.7, 0.6],  
        [0.5, 0.4, 0.3],  
        [0.2, 0.1, 0.0]])  
This output tensor reflects the denoised version of the input data, adjusted according to the noise level and model outputs.
***
## ClassDef ModelSamplingDiscreteDistilled
**ModelSamplingDiscreteDistilled**: The function of ModelSamplingDiscreteDistilled is to implement a refined discrete sampling strategy for generative models, optimizing the sampling process by reducing the number of timesteps while maintaining effective sigma calculations.

**attributes**: The attributes of this Class.
· original_timesteps: A constant value set to 50, representing the number of timesteps used in the distilled sampling process.  
· skip_steps: An integer calculated as the total number of timesteps divided by original_timesteps, determining how many steps to skip in the sampling process.  
· sigmas: A tensor that holds the computed sigma values for the sampling process, initialized during the class instantiation.  
· log_sigmas: A tensor that holds the logarithm of the sigma values, also initialized during the class instantiation.

**Code Description**: The ModelSamplingDiscreteDistilled class is a subclass of the ModelSamplingDiscrete class, which is designed to facilitate the sampling process in generative models. Upon initialization, it calls the constructor of its parent class, ModelSamplingDiscrete, to inherit its properties and methods. The original_timesteps attribute is set to 50, which defines the target number of timesteps for the sampling process.

During initialization, the skip_steps attribute is calculated by dividing the total number of timesteps (num_timesteps from the parent class) by original_timesteps. This value is crucial for determining how many timesteps to skip during the sampling process, effectively reducing the computational load while still allowing for meaningful sampling.

The class then initializes the sigmas_valid tensor, which is populated with sigma values that are selected from the parent class's sigmas tensor, based on the calculated skip_steps. This ensures that the sigma values used in the sampling process are appropriately spaced according to the reduced number of timesteps. The set_sigmas method from the parent class is called to register these computed sigma values.

The timestep method is overridden to adapt the behavior of the sigma calculation based on the new sampling strategy. It computes the closest timestep corresponding to a given sigma value by calculating the absolute differences between the logarithm of the sigma and the log_sigmas tensor, returning the appropriate timestep index.

The sigma method is also overridden to provide a way to retrieve the sigma value corresponding to a specific timestep. It performs linear interpolation between the log_sigma values based on the calculated indices, ensuring that the output is consistent with the reduced timestep structure.

This class is called by the patch method in the same module, which allows for the creation of an advanced sampling model by combining different sampling strategies. When the sampling type is set to "lcm" or "tcd", the ModelSamplingDiscreteDistilled class is utilized as the base for the sampling process, indicating its role in enhancing the sampling capabilities of the overall model.

**Note**: When using this class, it is essential to ensure that the model configuration is correctly set up, particularly regarding the number of timesteps and the sigma values. The class is designed to work with a reduced number of timesteps, which can significantly impact the quality and efficiency of the generated samples.

**Output Example**: A possible appearance of the code's return value when calling the sigma method with a specific timestep might look like this:
```python
sigma_value = model_sampling_discrete_distilled_instance.sigma(torch.tensor([5]))
print(sigma_value)  # Output: tensor([0.1234])
```
### FunctionDef __init__(self, model_config)
**__init__**: The function of __init__ is to initialize the ModelSamplingDiscreteDistilled class and set up the sigma values based on the model configuration.

**parameters**: The parameters of this Function.
· model_config: An optional configuration object that contains settings for the model.

**Code Description**: The __init__ function is responsible for initializing an instance of the ModelSamplingDiscreteDistilled class. It begins by calling the constructor of the parent class using `super().__init__(model_config)`, which ensures that any initialization defined in the parent class is executed with the provided model configuration.

Following this, the function calculates the `skip_steps`, which determines how many timesteps to skip based on the ratio of `num_timesteps` to `original_timesteps`. This is crucial for the sampling process, as it defines how the model will traverse through the timesteps during sampling.

The function then initializes a tensor `sigmas_valid` with zeros, having a size equal to `original_timesteps`. This tensor is populated in a loop, where it assigns values from the `sigmas` attribute of the class. The assignment is done in reverse order, ensuring that the valid sigma values are correctly aligned with the original timesteps while considering the skip steps. This step is essential for preparing the model to work with the appropriate sigma values during its operations.

Finally, the function calls `self.set_sigmas(sigmas_valid)`, which registers the computed valid sigma values. The `set_sigmas` function is designed to register the provided sigma values and their logarithmic counterparts as buffers in the model. This registration is important for maintaining the state of the model across different computations and ensuring that the sigma values are readily available for subsequent operations.

The relationship with the `set_sigmas` function is significant, as it directly influences how the model handles sigma values, which are critical for the sampling process. By ensuring that the sigma values are correctly set during initialization, the model is prepared for effective sampling operations.

**Note**: It is important to ensure that the model configuration passed to the __init__ function is correctly defined to avoid any issues during initialization. The proper calculation of skip steps and the registration of sigma values are crucial for the model's performance in sampling tasks.
***
### FunctionDef timestep(self, sigma)
**timestep**: The function of timestep is to compute the nearest time step indices based on the logarithm of the provided sigma values.

**parameters**: The parameters of this Function.
· sigma: A tensor representing the standard deviations for which the nearest time steps are to be calculated.

**Code Description**: The timestep function begins by calculating the logarithm of the input tensor sigma using the log() method. This logarithmic transformation is essential for the subsequent calculations, as it allows for a more manageable comparison of values. The function then computes the difference between the log_sigma and the log_sigmas tensor, which is a member variable of the class. This difference is reshaped to facilitate broadcasting, resulting in a tensor of distances. The absolute values of these distances are then taken, and the indices of the minimum values along dimension 0 are determined using the argmin() method. 

These indices represent the closest time steps corresponding to each element in the input sigma tensor. The resulting indices are reshaped to match the original shape of sigma and are scaled by the skip_steps attribute of the class. Finally, the function adjusts the indices by subtracting one from skip_steps to ensure they are correctly aligned with the intended time steps. The final output is converted to the same device as the input sigma tensor, ensuring compatibility for further computations.

**Note**: It is important to ensure that the log_sigmas tensor is properly initialized and that the skip_steps attribute is set correctly before calling this function. The input sigma should also be a valid tensor of standard deviations.

**Output Example**: If the input sigma tensor is [0.1, 0.5, 1.0] and assuming the log_sigmas tensor contains appropriate pre-computed values, the function may return a tensor such as [0, 1, 2], indicating the indices of the nearest time steps for each corresponding sigma value.
***
### FunctionDef sigma(self, timestep)
**sigma**: The function of sigma is to compute the exponential of a log-sigma value interpolated between two indices based on the given timestep.

**parameters**: The parameters of this Function.
· timestep: A tensor representing the current timestep, which is used to determine the appropriate log-sigma value.

**Code Description**: The sigma function takes a single parameter, timestep, which is expected to be a tensor. The function first normalizes the timestep by subtracting the number of skip steps minus one and dividing by the skip steps. This normalization is clamped to ensure that it remains within the bounds of 0 and the length of the log_sigmas array minus one. The resulting value, t, is then used to determine the indices for interpolation. 

The function calculates two indices: low_idx and high_idx, which correspond to the floor and ceiling of t, respectively. The fractional part of t, denoted as w, is computed to facilitate linear interpolation between the log-sigma values at these two indices. The log_sigma is then calculated as a weighted sum of the log_sigmas at low_idx and high_idx, using (1 - w) and w as weights. Finally, the function returns the exponential of log_sigma, converted to the same device as the original timestep tensor.

**Note**: It is important to ensure that the timestep tensor is compatible with the device of log_sigmas to avoid runtime errors. The function assumes that log_sigmas is a tensor of log-sigma values that has been precomputed and is accessible in the context where this function is called.

**Output Example**: If the input timestep tensor is [5], and assuming the log_sigmas tensor contains values [0.1, 0.2, 0.3, 0.4, 0.5], the function might return a tensor with a value around 1.2214, which is the exponential of the interpolated log-sigma value.
***
## FunctionDef rescale_zero_terminal_snr_sigmas(sigmas)
**rescale_zero_terminal_snr_sigmas**: The function of rescale_zero_terminal_snr_sigmas is to rescale the terminal signal-to-noise ratios (SNR) sigmas for a model's sampling process.

**parameters**: The parameters of this Function.
· sigmas: A tensor containing the original signal-to-noise ratios (SNR) values.

**Code Description**: The rescale_zero_terminal_snr_sigmas function takes a tensor of sigmas as input and performs a series of mathematical operations to rescale these values. Initially, it computes the cumulative product of alphas using the formula \( \text{alphas\_cumprod} = \frac{1}{(\text{sigmas}^2) + 1} \). The square root of this cumulative product is then calculated and stored in alphas_bar_sqrt.

The function then stores the first and last values of alphas_bar_sqrt for later use. It shifts the entire tensor so that the last timestep becomes zero by subtracting the last value from all elements. Subsequently, it scales the tensor such that the first timestep returns to its original value by multiplying it with the ratio of the first value to the difference between the first and last values.

After these adjustments, the function converts the alphas_bar_sqrt back to alphas_bar by squaring the values. The last value of alphas_bar is explicitly set to a very small number, \( 4.8973451890853435e-08 \), to ensure numerical stability. Finally, the function returns the square root of the ratio \( \frac{(1 - \text{alphas\_bar})}{\text{alphas\_bar}} \), which represents the rescaled sigmas.

This function is called within the patch method of the ModelSamplingDiscrete class. When the zsnr parameter is set to true, the patch method invokes rescale_zero_terminal_snr_sigmas to adjust the sigmas of the model sampling instance. This integration ensures that the model uses the rescaled sigmas for improved sampling performance, particularly in scenarios where the signal-to-noise ratio is critical.

**Note**: It is important to ensure that the input sigmas tensor is properly formatted and contains valid numerical values to avoid runtime errors during the calculations.

**Output Example**: A possible appearance of the code's return value could be a tensor with values representing the rescaled sigmas, such as:
```
tensor([1.0, 0.5, 0.25, ..., 0.000000048973451890853435])
```
## ClassDef ModelSamplingDiscrete
**ModelSamplingDiscrete**: The function of ModelSamplingDiscrete is to apply a specific sampling method to a model, allowing for advanced model sampling configurations.

**attributes**: The attributes of this Class.
· INPUT_TYPES: A class method that defines the required input types for the patching process, including the model, sampling method, and a boolean for zero signal-to-noise ratio (zsnr).
· RETURN_TYPES: Specifies the return type of the patch method, which is a modified model.
· FUNCTION: Indicates the name of the method that performs the main functionality, which is "patch".
· CATEGORY: Categorizes the class under "advanced/model".

**Code Description**: The ModelSamplingDiscrete class is designed to modify a given model by applying a specified sampling method. The class contains a class method, INPUT_TYPES, which outlines the necessary inputs: a model, a sampling method (with options such as "eps", "v_prediction", "lcm", and "tcd"), and a boolean parameter zsnr that defaults to False. The RETURN_TYPES attribute indicates that the output of the patch method will be a modified model.

The core functionality is encapsulated in the patch method, which takes the model and the specified sampling method as arguments. The method begins by cloning the input model to ensure that the original model remains unchanged. Depending on the chosen sampling method, the method assigns the appropriate sampling type and base class. For instance, if "lcm" or "tcd" is selected, it uses a different base class, ModelSamplingDiscreteDistilled.

A new class, ModelSamplingAdvanced, is dynamically created by inheriting from both the sampling base and the sampling type. This allows for the combination of functionalities from both classes. An instance of ModelSamplingAdvanced is then created using the model's configuration. If the zsnr parameter is set to True, the method rescales the sigmas of the model sampling instance.

Finally, the modified model is updated with the new model sampling object, and the method returns the modified model as a tuple.

The ModelSamplingDiscrete class is called from other parts of the project, such as modules/core.py, where it likely integrates with the broader model management and sampling framework. This integration allows for enhanced sampling capabilities within the overall model processing pipeline.

**Note**: When using the ModelSamplingDiscrete class, ensure that the correct sampling method is specified, as this will directly affect the behavior of the model. Additionally, consider the implications of setting zsnr to True, as it alters the sigma values used in the sampling process.

**Output Example**: A possible return value from the patch method could be a modified model object that includes the new sampling configuration, represented as a tuple: (modified_model_instance,).
### FunctionDef INPUT_TYPES(s)
**INPUT_TYPES**: The function of INPUT_TYPES is to define and return the required input types for a specific model sampling configuration.

**parameters**: The parameters of this Function.
· s: This parameter is not utilized within the function and serves as a placeholder for potential future use or for compatibility with other functions.

**Code Description**: The INPUT_TYPES function constructs a dictionary that specifies the required input types for a model sampling process. The returned dictionary contains a single key, "required", which itself maps to another dictionary detailing the specific inputs needed. 

The "model" key expects a single value of type "MODEL", indicating that a model object must be provided. The "sampling" key requires a list of options, specifically one of the following strings: "eps", "v_prediction", "lcm", or "tcd". This indicates that the user must select one of these predefined sampling methods. The "zsnr" key expects a boolean value, with a default setting of False, allowing the user to specify whether to use zero-shot noise reduction.

Overall, this function is crucial for ensuring that the necessary inputs are correctly defined and validated before proceeding with model sampling operations.

**Note**: It is important to ensure that the inputs conform to the specified types and options to avoid errors during the model sampling process. The boolean input for "zsnr" should be explicitly set to either True or False, with the default being False if not specified.

**Output Example**: An example of the return value from the INPUT_TYPES function would be:
{
    "required": {
        "model": ("MODEL",),
        "sampling": (["eps", "v_prediction", "lcm", "tcd"]),
        "zsnr": ("BOOLEAN", {"default": False}),
    }
}
***
### FunctionDef patch(self, model, sampling, zsnr)
**patch**: The function of patch is to modify a model's sampling strategy by integrating different sampling types and adjusting the sigma values based on the specified parameters.

**parameters**: The parameters of this Function.
· model: An instance of the model to be patched, which contains the configuration and sampling settings.  
· sampling: A string that specifies the type of sampling to be used, which can be "eps", "v_prediction", "lcm", or "tcd".  
· zsnr: A boolean flag indicating whether to rescale the sigma values based on the zero terminal signal-to-noise ratio.

**Code Description**: The patch function begins by cloning the provided model to create a modified version. It then determines the appropriate sampling base and type based on the value of the sampling parameter. The sampling_base is initially set to the ModelSamplingDiscrete class, which serves as the foundation for the sampling strategy.

Depending on the specified sampling type:
- If sampling is "eps", the sampling_type is set to the EPS class.
- If sampling is "v_prediction", the sampling_type is set to the V_PREDICTION class.
- If sampling is "lcm", the sampling_type is set to the LCM class, and the sampling_base is switched to ModelSamplingDiscreteDistilled.
- If sampling is "tcd", the sampling_type is again set to EPS, with the sampling_base also set to ModelSamplingDiscreteDistilled.

A new class, ModelSamplingAdvanced, is then defined, which inherits from both the selected sampling_base and sampling_type. This class is instantiated with the model's configuration, creating a model_sampling instance.

If the zsnr parameter is true, the function calls rescale_zero_terminal_snr_sigmas to adjust the sigmas of the model_sampling instance, ensuring that the sampling process utilizes the rescaled values for improved performance.

Finally, the function adds the newly created model_sampling instance to the cloned model as an object patch and returns the modified model.

The patch function is called by the patch_discrete function in the modules/async_worker.py file. This function takes a unet model and a scheduler name as input, invoking the patch method to apply the specified sampling strategy and returning the modified model. This demonstrates the integration of the patch function within a broader workflow, allowing for flexible model configurations based on different sampling strategies.

**Note**: When using the patch function, it is essential to ensure that the model and sampling parameters are correctly specified to avoid runtime errors. Additionally, the zsnr flag should be set based on the desired behavior regarding sigma rescaling.

**Output Example**: A possible output of the patch function could be a modified model instance that incorporates the specified sampling strategy, such as:
```python
modified_model = patch(original_model, "lcm", True)
```
#### ClassDef ModelSamplingAdvanced
**ModelSamplingAdvanced**: The function of ModelSamplingAdvanced is to serve as a specialized class for advanced sampling techniques in a discrete model context.

**attributes**: The attributes of this Class are inherited from its parent classes, sampling_base and sampling_type. Specific attributes are not defined within the ModelSamplingAdvanced class itself.

**Code Description**: The ModelSamplingAdvanced class is a subclass that inherits from two parent classes: sampling_base and sampling_type. This indicates that it is designed to extend or modify the functionality provided by these base classes. However, as it stands, the ModelSamplingAdvanced class does not introduce any new attributes or methods of its own; it merely serves as a placeholder or a marker for advanced sampling techniques that may be implemented in the future. The class structure suggests that it is intended to be part of a larger framework for sampling methods, potentially allowing for more complex behaviors or configurations that are specific to advanced sampling scenarios.

**Note**: When utilizing the ModelSamplingAdvanced class, it is important to understand the functionalities provided by the parent classes, sampling_base and sampling_type, as this class does not define any additional behavior on its own. Users should ensure they are familiar with the methods and attributes of these parent classes to effectively implement and utilize the advanced sampling techniques that this class is meant to facilitate.
***
***
## ClassDef ModelSamplingContinuousEDM
**ModelSamplingContinuousEDM**: The function of ModelSamplingContinuousEDM is to apply advanced model sampling techniques to a given model based on specified parameters.

**attributes**: The attributes of this Class.
· INPUT_TYPES: Defines the required input types for the class, including the model, sampling method, and sigma values.
· RETURN_TYPES: Specifies the return type of the class, which is a modified model.
· FUNCTION: Indicates the function name that will be executed, which is "patch".
· CATEGORY: Categorizes the class under "advanced/model".

**Code Description**: The ModelSamplingContinuousEDM class is designed to enhance a given model by applying various sampling techniques. It includes a class method, INPUT_TYPES, which outlines the necessary inputs for the class to function. These inputs include a model object, a sampling method (which can be one of three options: "v_prediction", "edm_playground_v2.5", or "eps"), and two floating-point values representing the maximum and minimum sigma values.

The class has a method called patch, which takes the specified inputs and performs the following operations:
1. It clones the provided model to create a new instance.
2. Based on the selected sampling method, it determines the appropriate sampling type and sets the sigma data accordingly. For example, if "edm_playground_v2.5" is chosen, it also initializes a latent format specific to that sampling method.
3. It defines a nested class, ModelSamplingAdvanced, which inherits from both ModelSamplingContinuousEDM and the selected sampling type. This allows for the integration of the chosen sampling method into the model.
4. An instance of ModelSamplingAdvanced is created, and its parameters are set using the provided sigma values.
5. The modified model is then updated with the new model sampling object and, if applicable, the latent format.

The return value of the patch method is a tuple containing the modified model. This class is particularly useful in scenarios where advanced sampling techniques are needed to improve model performance, and it can be called from other modules, such as modules/core.py, to integrate these enhancements into broader workflows.

**Note**: When using this class, ensure that the sigma values are within the specified range (0.0 to 1000.0) and that the sampling method is correctly selected to avoid errors during execution.

**Output Example**: A possible appearance of the code's return value could be a modified model object that includes the applied sampling techniques and configurations, ready for further processing or evaluation.
### FunctionDef INPUT_TYPES(s)
**INPUT_TYPES**: The function of INPUT_TYPES is to define and return the required input types for a model sampling configuration.

**parameters**: The parameters of this Function.
· parameter1: s - This parameter is typically used to represent the state or context in which the function is called, although it is not utilized within the function body.

**Code Description**: The INPUT_TYPES function constructs a dictionary that specifies the required input types for a model sampling process. The dictionary contains a single key, "required", which maps to another dictionary detailing the specific inputs needed. 

1. **model**: This input is expected to be of type "MODEL", indicating that it should conform to a predefined model structure or type.
2. **sampling**: This input is a list that allows selection from three specific string options: "v_prediction", "edm_playground_v2.5", and "eps". This indicates the type of sampling method to be used.
3. **sigma_max**: This input is of type "FLOAT" and has a default value of 120.0. It also includes constraints such as a minimum value of 0.0, a maximum value of 1000.0, a step increment of 0.001, and a specification that rounding is not required.
4. **sigma_min**: Similar to sigma_max, this input is also of type "FLOAT" with a default value of 0.002. It shares the same constraints regarding minimum, maximum, step, and rounding options.

The function effectively organizes these inputs into a structured format that can be easily referenced and validated in the context of model sampling.

**Note**: When utilizing this function, ensure that the inputs conform to the specified types and constraints to avoid errors during model sampling. The function does not perform any validation; it merely defines the expected structure.

**Output Example**: An example of the return value from the INPUT_TYPES function would be:
{
    "required": {
        "model": ("MODEL",),
        "sampling": (["v_prediction", "edm_playground_v2.5", "eps"],),
        "sigma_max": ("FLOAT", {"default": 120.0, "min": 0.0, "max": 1000.0, "step": 0.001, "round": False}),
        "sigma_min": ("FLOAT", {"default": 0.002, "min": 0.0, "max": 1000.0, "step": 0.001, "round": False}),
    }
}
***
### FunctionDef patch(self, model, sampling, sigma_max, sigma_min)
**patch**: The function of patch is to configure and apply model sampling strategies based on specified parameters.

**parameters**: The parameters of this Function.
· parameter1: model - The model instance that will be cloned and modified with new sampling strategies.  
· parameter2: sampling - A string that specifies the type of sampling to be used, which can be "eps", "v_prediction", or "edm_playground_v2.5".  
· parameter3: sigma_max - The maximum value for the sigma parameter, influencing the range of noise levels in the sampling process.  
· parameter4: sigma_min - The minimum value for the sigma parameter, which defines the lower limit of noise levels in the sampling process.

**Code Description**: The patch function begins by creating a clone of the provided model instance to ensure that the original model remains unaltered. It initializes a variable `latent_format` to None and sets a default value for `sigma_data` to 1.0. The function then determines the appropriate sampling type based on the input parameter `sampling`. If the sampling type is "eps", it assigns the EPS class to `sampling_type`. For "v_prediction", it assigns the V_PREDICTION class, and for "edm_playground_v2.5", it assigns the EDM class while also adjusting `sigma_data` to 0.5 and initializing `latent_format` with an instance of SDXL_Playground_2_5.

Next, the function defines a new class, ModelSamplingAdvanced, which inherits from both ModelSamplingContinuousEDM and the determined sampling type. An instance of this new class is created, and the sigma parameters are set using the set_parameters method, which is crucial for configuring the noise levels used in the sampling process. The cloned model then has the new model sampling object and, if applicable, the latent format object added to it via the add_object_patch method.

The patch function ultimately returns a tuple containing the modified model. This function is called by the patch_edm function, which is part of the async_worker module. The patch_edm function takes a unet model and a scheduler name, invoking the patch function with specific sigma values (120.0 for sigma_max and 0.002 for sigma_min). This integration allows for the application of advanced sampling strategies tailored to the unet model, enhancing its performance during the sampling process.

**Note**: It is essential to ensure that the sigma_min and sigma_max values are set appropriately, as they directly affect the range of noise levels used in the sampling process. Incorrect values may lead to suboptimal model performance.

**Output Example**: A possible output of the patch function could be a modified model instance that incorporates the specified sampling strategy and parameters. For instance, if the input model is a neural network designed for image generation, the output might be a new model capable of generating images with enhanced noise handling based on the selected sampling method.
#### ClassDef ModelSamplingAdvanced
**ModelSamplingAdvanced**: The function of ModelSamplingAdvanced is to extend the continuous sampling capabilities provided by the ModelSamplingContinuousEDM class, potentially adding additional functionality or modifying behavior for specific use cases.

**attributes**: The attributes of this Class.
· There are no additional attributes defined in the ModelSamplingAdvanced class itself, as it inherits all attributes from the ModelSamplingContinuousEDM class.

**Code Description**: The ModelSamplingAdvanced class inherits from the ModelSamplingContinuousEDM class, which is part of the ldm_patched.modules.model_sampling module. By extending ModelSamplingContinuousEDM, ModelSamplingAdvanced inherits its continuous sampling mechanisms, including all attributes and methods related to sigma-based sampling strategies. This design allows ModelSamplingAdvanced to utilize the established functionality of ModelSamplingContinuousEDM while providing a framework for further customization or enhancement.

The ModelSamplingContinuousEDM class is responsible for implementing a continuous sampling mechanism that utilizes sigma values to facilitate sampling in deep learning models. It initializes with parameters that define the range of sigma values and provides methods to manipulate and access these values. The inherited methods and properties from ModelSamplingContinuousEDM, such as sigma_min, sigma_max, timestep, sigma, and percent_to_sigma, are available in ModelSamplingAdvanced, allowing it to perform continuous sampling operations seamlessly.

The relationship between ModelSamplingAdvanced and ModelSamplingContinuousEDM indicates that ModelSamplingAdvanced is likely designed for specific scenarios where the base functionality needs to be adapted or extended. This could involve overriding methods, adding new methods, or modifying existing behavior to suit particular model requirements or sampling strategies.

**Note**: When utilizing the ModelSamplingAdvanced class, it is essential to understand the underlying mechanisms of the inherited ModelSamplingContinuousEDM class to ensure effective implementation and avoid unexpected behavior. Proper configuration of the model parameters is crucial for achieving the desired sampling outcomes.
***
***
## ClassDef RescaleCFG
**RescaleCFG**: The function of RescaleCFG is to modify the configuration of a model by applying a rescaling technique based on a specified multiplier.

**attributes**: The attributes of this Class.
· INPUT_TYPES: Defines the required input types for the class method.
· RETURN_TYPES: Specifies the type of output returned by the class method.
· FUNCTION: Indicates the name of the function that will be executed.
· CATEGORY: Categorizes the class within the broader context of the project.

**Code Description**: The RescaleCFG class is designed to adjust the configuration of a model by applying a rescaling function. It contains a class method INPUT_TYPES that specifies the required inputs: a model and a multiplier. The multiplier is a floating-point number that defaults to 0.7 and must be within the range of 0.0 to 1.0. The class also defines RETURN_TYPES, which indicates that the output will be of type "MODEL". The FUNCTION attribute specifies that the method to be executed is named "patch".

The core functionality of the RescaleCFG class is encapsulated in the patch method. This method takes in a model and a multiplier as parameters. Inside the patch method, a nested function named rescale_cfg is defined, which performs the actual rescaling operation. The rescale_cfg function processes the model's output by manipulating the conditional and unconditional inputs, adjusting their scales based on the provided sigma values, and applying the specified multiplier to achieve the final output.

The rescale_cfg function first retrieves necessary inputs from the arguments, including conditional and unconditional tensors, as well as the sigma values. It then rescales the original input based on these values. The rescaling is performed by calculating the standard deviation of the conditional and unconditional outputs, which are used to adjust the final output accordingly. The final output is computed by blending the rescaled values with the original model output, weighted by the multiplier.

After defining the rescale_cfg function, the patch method clones the input model and sets the model's sampler configuration function to the newly defined rescale_cfg function. Finally, the method returns the modified model as a tuple.

**Note**: When using the RescaleCFG class, ensure that the input model is compatible with the expected input types and that the multiplier is set within the defined range. This class is intended for advanced model manipulation and should be used with an understanding of the underlying model architecture.

**Output Example**: The output of the patch method will be a modified model that incorporates the rescaling logic. The return value will be a tuple containing the modified model instance, which can be utilized in further processing or inference tasks.
### FunctionDef INPUT_TYPES(s)
**INPUT_TYPES**: The function of INPUT_TYPES is to define and return the required input types for a specific model configuration.

**parameters**: The parameters of this Function.
· s: This parameter is a placeholder that is not utilized within the function body.

**Code Description**: The INPUT_TYPES function returns a dictionary that specifies the required input types for a model configuration. The returned dictionary contains a single key, "required", which itself maps to another dictionary. This inner dictionary defines two required inputs: "model" and "multiplier". 

- The "model" input is expected to be of type "MODEL", indicating that it should correspond to a predefined model type within the system.
- The "multiplier" input is of type "FLOAT" and includes additional constraints: it has a default value of 0.7, a minimum value of 0.0, a maximum value of 1.0, and a step increment of 0.01. This means that the multiplier can be adjusted within the specified range, allowing for fine-tuning of the model's behavior.

The structure of the returned dictionary is crucial for ensuring that the necessary inputs are provided when configuring the model, thereby facilitating proper functionality and performance.

**Note**: It is important to ensure that the inputs conform to the specified types and constraints to avoid errors during model execution. The "multiplier" should be carefully set within its defined range to achieve the desired outcomes.

**Output Example**: A possible appearance of the code's return value could be:
{
    "required": {
        "model": ("MODEL",),
        "multiplier": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01})
    }
}
***
### FunctionDef patch(self, model, multiplier)
**patch**: The function of patch is to modify the configuration of a model by applying a rescaling technique to its outputs based on certain parameters.

**parameters**: The parameters of this Function.
· model: The model instance that is to be modified with the new configuration function.  
· multiplier: A float value that determines the weight of the rescaled output in the final output calculation.

**Code Description**: The patch function defines an inner function called rescale_cfg, which performs the actual rescaling of the model's outputs. The rescale_cfg function takes a dictionary of arguments, which includes the conditional input (cond), unconditional input (uncond), conditional scale (cond_scale), and sigma (sigma). 

The sigma value is reshaped to match the dimensions of the conditional input. The original input (x_orig) is then adjusted based on the sigma value to compute a new variable x. The conditional and unconditional inputs are also adjusted to account for the sigma, allowing for the calculation of a new variable x_cfg that combines the conditional and unconditional inputs scaled by cond_scale.

Next, the function calculates the standard deviation of the conditional input (ro_pos) and the rescaled configuration (ro_cfg). The rescaled output (x_rescaled) is computed by normalizing x_cfg using the ratio of these standard deviations. Finally, the function combines the rescaled output and the original x_cfg using the provided multiplier to produce the final output (x_final).

The patch function then clones the provided model and sets its configuration sampling function to the rescale_cfg function, effectively modifying the model's behavior. The function returns a tuple containing the modified model.

**Note**: It is important to ensure that the model being patched is compatible with the rescale_cfg function, and that the inputs provided in the arguments dictionary are correctly formatted to avoid runtime errors.

**Output Example**: A possible appearance of the code's return value could be a tuple containing the modified model instance, which would be ready to use with the new rescaling configuration applied. For example: (modified_model_instance,)
#### FunctionDef rescale_cfg(args)
**rescale_cfg**: The function of rescale_cfg is to rescale the conditional and unconditional outputs of a model based on a specified scaling factor and noise level.

**parameters**: The parameters of this Function.
· args: A dictionary containing the necessary inputs for the function, including:
  - cond: The conditional output from the model.
  - uncond: The unconditional output from the model.
  - cond_scale: A scaling factor applied to the conditional output.
  - sigma: A tensor representing the noise level.
  - input: The original input tensor to be processed.

**Code Description**: The rescale_cfg function performs a series of operations to adjust the conditional and unconditional outputs of a model based on the provided scaling factor (cond_scale) and noise level (sigma). 

Initially, the function extracts the relevant values from the input dictionary `args`. The noise level `sigma` is reshaped to match the dimensions of the conditional output `cond`. The original input tensor `x_orig` is then adjusted by dividing it by the sum of the square of `sigma` and 1.0, which effectively normalizes the input based on the noise level.

Next, the function computes the adjusted conditional and unconditional outputs. The conditional output `cond` is modified by subtracting the difference between the original input and the conditional output, scaled by the square root of the sum of the square of `sigma` and 1.0, and then divided by `sigma`. A similar operation is performed for the unconditional output `uncond`.

The function then calculates the final conditional output `x_cfg` by combining the adjusted conditional and unconditional outputs, weighted by the `cond_scale`. The standard deviation of both the conditional output and the rescaled output is computed to facilitate further adjustments.

Finally, the function rescales the conditional output based on the ratio of the standard deviations and combines it with the original rescaled output to produce the final output. The result is adjusted by subtracting the difference between the normalized input and the final output scaled by the noise level, yielding the final processed tensor.

**Note**: It is important to ensure that the input tensors have compatible dimensions and that the `sigma` tensor is appropriately shaped to avoid broadcasting issues during calculations.

**Output Example**: A possible return value of the function could be a tensor that represents the adjusted input after applying the rescaling operations, which maintains the original input's structure while incorporating the effects of the conditional scaling and noise adjustments. For instance, if the original input was a tensor of shape (batch_size, channels, height, width), the output would also be of the same shape, reflecting the rescaled values.
***
***
